# qiushibaike_spider

###依照上一个爬取百度百科页面的实例，这次写了一个爬取糗事百科的段子，思路基本上是差不多的，只是这次是爬取多个页面的内容，并且是爬取一整页的段子，使用了字典+列表的方式，之后将爬取到的信息循环输出到html页面中进行展示，同时写到文本文件中进行存储。

###在执行爬取的时候，貌似出了点小问题，程序并没有爬取所有的35页的内容，只爬取了3页段子，就停止了，不知道是不是因为连接不稳定。后续再查看原因吧。

###最后的效果如下

1. html页面效果
![http://i.imgur.com/z2KSikh.png](http://i.imgur.com/z2KSikh.png)

2. 输出到txt文件效果
![http://i.imgur.com/LXFCIMB.png](http://i.imgur.com/LXFCIMB.png)